#!/usr/bin/env python

analytics_settings(False)

update_settings(max_parallel_updates=3)

local_resource(
    "code-server",
    serve_cmd=[
        "bash",
        "-c",
        """
            cd ~/m
            exec code-server --auth none --port 13337
            """,
    ],
)

local_resource(
    "hugo",
    serve_cmd=[
        "bash",
        "-c",
        """
            cd ~/m/defn/dev/www
            npm install
            exec npm run dev
            """,
    ],
)

local_resource(
    "temporal",
    serve_cmd=[
        "bash",
        "-c",
        """
            cd ~/m
            exec temporal server start-dev
            """,
    ],
)

local_resource(
    "buildkite",
    serve_cmd=[
        "bash",
        "-c",
        """
            cd ~/m
            make ci timeout=3600
            """,
    ],
)

#local_resource(
#    "argocd-forward",
#    serve_cmd=[
#        "bash",
#        "-c",
#        """
#            set -exu
#
#            cd ~/m
#
#            while true; do
#                uptime
#                if ! kubectl --context k3d-dfd-argocd port-forward deployment/argocd-server 8080:8080; then
#                    sleep 5
#                fi
#            done
#            """,
#    ],
#)

local_resource(
    "k3d",
    cmd=[
        "bash",
        "-c",
        """
            set -exu

            nme="dfd"

            cd ~/m

            # deploy k3d, argocd
            rm -vf ~/.kube/config*
            env KUBECONFIG=$HOME/.kube/config k3d cluster delete ${nme} || true
            env KUBECONFIG=$HOME/.kube/config k3d cluster create ${nme} --config k3d.yaml
            docker update --restart=no k3d-${nme}-server-0

            (cd c/${nme} && make secrets)

            docker exec -i k3d-${nme}-server-0  mount bpffs -t bpf /sys/fs/bpf
            docker exec -i k3d-${nme}-server-0  mount --make-shared /sys/fs/bpf
            docker exec -i k3d-${nme}-server-0  mkdir -p /run/cilium/cgroupv2
            docker exec -i k3d-${nme}-server-0  mount -t cgroup2 none /run/cilium/cgroupv2
            docker exec -i k3d-${nme}-server-0  mount --make-shared /run/cilium/cgroupv2

            kubectl --context k3d-${nme} apply -f k/r/k3d-${nme}-bootstrap-cert-manager-crds/main.yaml
            kubectl --context k3d-${nme} apply -f k/r/k3d-${nme}-bootstrap-cilium-bootstrap/main.yaml
            kubectl --context k3d-${nme} apply -f k/r/k3d-${nme}-argo-cd/main.yaml 

            # dedicated kubectl config for argocd
            cp $HOME/.kube/config $HOME/.kube/config.argocd
            (
                export KUBECONFIG=$HOME/.kube/config.argocd
                eval "$(kubectl config view -o json  | jq -r --arg cluster k3d-${nme} --arg namespace argocd '.contexts[] | select(.name == $cluster).context | "kubectl config set-context \\(.cluster)-argocd --cluster=\\(.cluster) --user=\\(.user) --namespace=\\($namespace)"')"
                kubectl config use-context k3d-${nme}-argocd
            )

            # switch back to the default config
            kubectl config use-context k3d-${nme}

            # needed for argocd password generation
            sudo apt install -y apache2-utils

            # wait until argocd is able to deploy to k3d
            while true; do
                # patch argocd admin password
                if kubectl --context k3d-${nme}-argocd patch secret argocd-secret   -p '{"stringData": { "admin.password": "'$(htpasswd -bnBC 10 "" admin | tr -d ':\\n')'"}}'; then
                    # add k3d to argocd
                    if env KUBECONFIG=$HOME/.kube/config.argocd argocd cluster add k3d-${nme} --yes --core --in-cluster; then
                        break
                    fi
                fi
                sleep 5
            done

            # deploy the cluster app-of-apps
            kubectl --context k3d-${nme} apply -f e/k3d-${nme}.yaml

            # background app-of-apps syncing
            while true; do 
                if env KUBECONFIG=$HOME/.kube/config.argocd argocd --core app sync --timeout 60 k3d-${nme} >/dev/null 2>&1; then break; fi
                sleep 30
            done &

            for v in 0 1; do
                break

                # wait until vcluster is ready
                while true; do 
                    if vcluster --context k3d-${nme} connect vcluster -n "k3d-${nme}-vc${v}" --server=$(kubectl --context k3d-${nme} get nodes -o json | jq -r '.items[].metadata.annotations["k3s.io/internal-ip"]'):$((8443 + v)) --insecure --update-current=false --kube-config-context-name vcluster-k3d-${nme}-vc${v} --kube-config $HOME/.kube/config.vc${v}; then break; fi
                    sleep 5
                done

                # add vcluster to argocd
                while true; do
                    if env KUBECONFIG="$HOME/.kube/config.argocd:$HOME/.kube/config.vc${v}" argocd --kube-context k3d-${nme}-argocd cluster --core add "vcluster-k3d-${nme}-vc${v}" --yes; then break; fi
                    sleep 5
                done

                # start syncing vcluster
                while true; do
                    if env KUBECONFIG=$HOME/.kube/config.argocd argocd --core app sync --timeout 30 k3d-${nme}-vcluster-k3d-${nme}-vc${v}; then break; fi
                    sleep 5
                done &
            done

            env KUBECONFIG=$HOME/.kube/config.argocd argocd --core app wait --sync k3d-${nme}

            uptime
            """,
    ],
)
