#!/usr/bin/env bash

set -eu
cd ~/m

infra_name="$(cd ~/m/c/$(uname -n) && cue eval -e infra_name | jq -r .)"

function make_init {
	# create k3s registry
	docker run -d -p 5000:5000 --restart=always --name registry registry:2 || true
}

function make_linkerd {
	# CA
	step certificate create root.linkerd.cluster.local ca.crt ca.key --profile root-ca --no-password --insecure

	# signing cluster
	step certificate create identity.linkerd.cluster.local cluster.crt cluster.key --profile intermediate-ca --not-after 8760h --no-password --insecure --ca ca.crt --ca-key ca.key

	# install linkerd cluster
	linkerd --context ${infra_name} install --crds | k --context ${infra_name} apply -f -
	linkerd --context ${infra_name} install --identity-trust-anchors-file ca.crt --identity-issuer-certificate-file cluster.crt --identity-issuer-key-file cluster.key | k --context ${infra_name} apply -f -
	linkerd --context ${infra_name} check

	# install viz cluster
	linkerd --context ${infra_name} viz install --set dashboard.enforcedHostRegexp=^ | k --context ${infra_name} apply -f -

	# install mc cluster
	linkerd --context ${infra_name} multicluster install --gateway=false | k --context ${infra_name} apply -f -
	linkerd --context ${infra_name} multicluster check
}

function make_vc {
	for v in $(cd c/${infra_name} && cue export --out json -e infra.parent.vclusters | jq -r '.[]'); do
		i="${v#vc}"
		# wait until vcluster is ready
		while true; do
			if vcluster --context ${infra_name} connect vcluster -n "${infra_name}-${v}-vcluster" --server=$(kubectl get --context ${infra_name} -n ${infra_name}-${v}-vcluster svc vcluster -o json | jq -r '.spec.clusterIP'):443 --update-current=false --kube-config-context-name ${infra_name}-"${v}" --kube-config "$HOME"/.kube/config."${v}"; then
				break
			fi
			sleep 5
		done

		# add vcluster to argocd
		while true; do
			if env KUBECONFIG="$HOME/.kube/config.argocd:$HOME/.kube/config.${v}" argocd --kube-context ${infra_name}-argocd cluster --core add "${infra_name}-${v}" --yes; then break; fi
			sleep 5
		done
	done
}

function make_down {
	sudo ip link delete cilium_host || true
	sudo ip link delete cilium_net || true
	sudo ip link delete cilium_vxlan || true

	sudo iptables-save | grep -iv cilium | sudo iptables-restore
	sudo ip6tables-save | grep -iv cilium | sudo ip6tables-restore

	/usr/local/bin/k3s-uninstall.sh || true
}

function make_up {
	rm -vf ~/.kube/config*

	set +x
	local TOKEN="$(curl -sSL -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600")"
	local container_ip="$(curl -sSL -H "X-aws-ec2-metadata-token: $TOKEN" http://169.254.169.254/latest/meta-data/local-ipv4)"
	set -x
	sudo mkdir -p /etc/rancher/k3s
	sudo cp registries.yaml /etc/rancher/k3s/
	k3sup install --local --context ${infra_name} --local-path ~/.kube/config --merge \
		--k3s-version "$(cd c/${infra_name} && cue export --out json -e infra_k3s_version | jq -r . | cut -d: -f2 | sed 's#-#+#')" \
		--k3s-extra-args "--node-ip "${container_ip}" --disable-network-policy --disable=traefik --flannel-backend=none --kube-apiserver-arg=--service-account-issuer=$(cd c/${infra_name} && cue export --out json -e discovery_url | jq -r .)/openid --kube-apiserver-arg=--api-audiences=https://kubernetes.default.svc.cluster.local,sts.amazonaws.com --tls-san=${infra_name}" 

	# oidc
	(cd c/${infra_name} && make secrets)

	kubectl --context ${infra_name} apply -f k/r/${infra_name}-manual-cert-manager-crds/main.yaml
	kubectl --context ${infra_name} apply -f k/r/${infra_name}-manual-linkerd-crds/main.yaml
	kubectl --context ${infra_name} apply -f k/r/${infra_name}-manual-cilium-bootstrap/main.yaml
	kubectl --context ${infra_name} create ns argocd
	kubectl --context ${infra_name} apply -f k/r/${infra_name}-cluster-argo-cd/main.yaml

	# dedicated kubectl config for argocd
	cp $HOME/.kube/config $HOME/.kube/config.argocd
	(
		export KUBECONFIG=$HOME/.kube/config.argocd
		eval "$(kubectl config view -o json | jq -r --arg cluster ${infra_name} --arg namespace argocd '.contexts[] | select(.name == $cluster).context | "kubectl config set-context \(.cluster)-argocd --cluster=\(.cluster) --user=\(.user) --namespace=\($namespace)"')"
		kubectl config use-context ${infra_name}-argocd
	)

	# switch back to the default config
	kubectl config use-context ${infra_name}

	env KUBECONFIG=$HOME/.kube/config.argocd kubectl -n argocd rollout status deployment/argocd-server
	env KUBECONFIG=$HOME/.kube/config.argocd kubectl -n argocd rollout status deployment/argocd-repo-server

	# patch argocd admin password
	env KUBECONFIG=$HOME/.kube/config.argocd kubectl patch secret argocd-secret -p '{"stringData": { "admin.password": "'$(htpasswd -bnBC 10 "" admin | tr -d ':\n')'"}}'

	# add k3s to argocd
	while true; do
		if env KUBECONFIG=$HOME/.kube/config.argocd argocd cluster add ${infra_name} --name ${infra_name}-cluster --yes --core --in-cluster; then
			break
		fi
		sleep 5
	done

	# deploy the cluster app-of-apps
	kubectl --context ${infra_name} apply -f e/${infra_name}-cluster.yaml

	# background app-of-apps syncing
	while true; do
		if env KUBECONFIG=$HOME/.kube/config.argocd argocd --core app sync --timeout 60 ${infra_name}-cluster >/dev/null 2>&1; then break; fi
		sleep 30
	done &
}

function main {
	local cmd
	cmd="$1"
	shift

	"make_${cmd}"
}

time main "${1}"
uptime
