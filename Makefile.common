repo ?=
cache ?=
push ?= --push
dummy_ip ?= 169.254.32.1
workdir ?= /home/ubuntu
tilt_port ?= 10350
k3d_name ?= $(shell uname -n | cut -d. -f1)
context ?= k3d-$(k3d_name)
podname ?= $(k3d_name)-0
control ?= $(shell uname -n | sed s/-0//)

trust-ca:
	sudo security add-trusted-cert -d -r trustRoot -k ~/Library/Keychains/login.keychain-db etc/ca.crt

dummy:
	for ip in $(dummy_ip); do if ! ifconfig lo0 | grep "inet $$ip"; then sudo ifconfig lo0 alias "$$ip" netmask 255.255.255.255; fi; done;

dummy-docker:
	docker run --rm -i --privileged --network=host --pid=host alpine nsenter -t 1 -m -u -n -i -- \
		bash -c "ip link add dummy0 type dummy; ip addr add $(dummy_ip)/32 dev dummy0; ip link set dev dummy0 up"

unlock:
	cd ~/.password-store && git crypt unlock
	pass hello
	$(MAKE) vault-unseal

dev:
	@true

dev-meh:
	@if [[ ! -d work/password-store ]]; then if flock -n ~/.home.lock -c '~/bin/e $(MAKE) init'; then true; fi; fi

init:
	-git pull
	$(MAKE) init-inner
	$(MAKE) init-site

init-inner:
	-git clone git@github.com:defn/dev work/dev
	-git clone git@github.com:jojomomojo/password-store work/password-store
	-cd work/password-store && git crypt unlock && git pull
	$(MAKE) vault-unseal
	$(MAKE) kubeconfig

tilt:
	env tilt up --context pod --port $(tilt_port)

login:
	$(MAKE) argocd-login

argocd-login:
	argocd login --insecure argocd-server.argocd.svc --username admin --password adminadmin \
		|| (argocd login --insecure argocd-server.argocd.svc --username admin --password "$$(kubectl --context argocd get -o json secret argocd-initial-admin-secret | jq -r '.data.password | @base64d')" \
				&& argocd account update-password --new-password adminadmin --current-password "$$(kubectl --context argocd get -o json secret argocd-initial-admin-secret | jq -r '.data.password | @base64d')")

sync:
	-kubectl --context pod create namespace argocd
	kustomize build --enable-helm k/argocd | kubectl --context argocd apply -f -
	kubectl --context argocd rollout status deployment argocd-server --watch
	sleep 10; $(MAKE) argocd-login
	kubectl --context argocd apply -f e/$(control)/ns.yaml
	kubectl --context argocd apply -f e/$(control)/no-ns.yaml

	argocd --kube-context argocd app sync argocd --local k/argocd --assumeYes --prune --retry-limit 10
	argocd --kube-context argocd app wait argocd

	argocd --kube-context cert-manager app sync cert-manager --local k/cert-manager --assumeYes --prune --retry-limit 10
	argocd --kube-context cert-manager app wait cert-manager

	argocd --kube-context kyverno app sync kyverno --local k/kyverno --assumeYes --prune --retry-limit 10
	argocd --kube-context kyverno app wait kyverno

	argocd --kube-context external-secrets app sync external-secrets --local k/external-secrets --assumeYes --prune --retry-limit 10
	argocd --kube-context external-secrets app wait external-secrets

	argocd --kube-context argocd app sync argo-workflows --local k/argo-workflows --assumeYes --prune --retry-limit 10
	argocd --kube-context argocd app wait argo-workflows

	argocd --kube-context argocd app sync argo-events --local k/argo-events --assumeYes --prune --retry-limit 10
	argocd --kube-context argocd app wait argo-events

	if argocd --kube-context argocd app sync traefik --local k/traefik --assumeYes --prune --retry-limit 10; then argocd --kube-context argocd app wait traefik; $(MAKE) cert || true; fi
	
	kubectl --context argocd apply -f e/$(control).yaml
	sleep 5
	argocd --kube-context argocd app sync sets-$(control) --local e/$(control) --assumeYes --prune --retry-limit 10
	argocd --kube-context argocd app wait sets-$(control)

vc0 vc1:
	set -x; for v in "$@"; do \
		while true; do if kubectl --context pod wait -n "$$v" -l statefulset.kubernetes.io/pod-name="$$v"-0 --for=condition=Ready pod; then break; fi; argocd --kube-context argocd app sync "$$v" --local "k/$$v" --assumeYes --prune --retry-limit 10; sleep 1; done; \
		argocd --kube-context argocd app wait "$$v"; \
		"$$v" get ns; \
		~/bin/e env KUBECONFIG=$$KUBECONFIG_ALL argocd cluster add --upsert "loft-vcluster_$${v}_$${v}_loft-cluster" --name "$$v" --yes; \
		while true; do if [[ "$$(argocd cluster get "$$v" --output json | jq -r '.name')" == "$$v" ]]; then break; fi; sleep 1; done; \
		kubectl --context argocd apply -f "k/sets/$$v.yaml"; \
		case "$$v" in \
			vc0) \
				argocd --kube-context argocd app sync vc0-kuma-global --local k/vc0-kuma-global --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc0-kuma-global; \
				argocd --kube-context argocd app sync vc0-demo --local k/vc0-demo --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc0-demo; \
				;; \
			vc1) \
				argocd --kube-context argocd app sync vc1-kuma-remote --local k/vc1-kuma-remote --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc1-kuma-remote; \
				argocd --kube-context argocd app sync vc1-knative --local k/vc1-knative --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc1-knative; \
				argocd --kube-context argocd app sync vc1-kourier --local k/vc1-kourier --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc1-kourier; \
				argocd --kube-context argocd app sync vc1-kong --local k/vc1-kong --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc1-kong; \
				argocd --kube-context argocd app sync vc1-demo --local k/vc1-demo --assumeYes --prune --retry-limit 10; \
				argocd --kube-context argocd app wait vc1-demo; \
				;; \
		esac; \
	done

kubeconfig:
	sudo cp /run/secrets/kubernetes.io/serviceaccount/ca.crt /usr/local/share/ca-certificates/
	sudo cp ~/etc/ca.crt /usr/local/share/ca-certificates/
	sudo update-ca-certificates
	kubectl config set-cluster pod --server=https://kubernetes.default.svc.cluster.local --embed-certs --certificate-authority=/run/secrets/kubernetes.io/serviceaccount/ca.crt
	kubectl config set-credentials pod --token="$$(cat /run/secrets/kubernetes.io/serviceaccount/token)"
	kubectl config set-context pod --cluster=pod --user=pod
	kubectl config set-cluster argocd --server=https://kubernetes.default.svc.cluster.local --embed-certs --certificate-authority=/run/secrets/kubernetes.io/serviceaccount/ca.crt
	kubectl config set-credentials argocd --token="$$(cat /run/secrets/kubernetes.io/serviceaccount/token)"
	kubectl config set-context argocd --cluster=pod --user=argocd --namespace argocd
	kubectl config use-context pod
	skaffold config set --kube-context pod local-cluster true
	#kumactl config control-planes add --overwrite --name pod --address http://kuma-control-plane-x-kuma-x-vc0.vc0.svc:5681

asdf:
	cat .tool-versions| awk '{print $$1}' | while read -r a; do asdf list-all "$$a" | sed "s#^#$$a #"; done | sort > .tool-versions-all

attach:
	code --folder-uri vscode-remote://k8s-container+context=$(context)+namespace=default+podname=$(podname)+name=dev+$(workdir)
	-kubectl get events -w

attach-remo:
	code --folder-uri vscode-remote://k8s-container+context=remo+namespace=default+podname=dev-0+name=dev+$(workdir)

cluster:
	git pull
	$(MAKE) cluster-inner name=$(context) ip=$(ip)

cluster-inner:
	cd d/k3d && $(MAKE) build name=$(context)
	-k3d cluster delete $(k3d_name)
	if [[ -x "$$(type -P tailscale)" ]]; then if tailscale ip 2>&1 | grep NeedsLogin; then sudo tailscale up; fi; fi
	k3d cluster create $(k3d_name) --config k3d.yaml --k3s-node-label env=$(k3d_name)@server:0
	docker update --restart=no k3d-$(k3d_name)-server-0
	docker exec k3d-$(k3d_name)-server-0 touch /etc/passwd

vault-unseal:
	pass Unseal_Key_1 | curl -sSL -X PUT -d @<(jq -nrR 'inputs|{key:.}|@json') http://localhost:8200/v1/sys/unseal
	pass Unseal_Key_3 | curl -sSL -X PUT -d @<(jq -nrR 'inputs|{key:.}|@json') http://localhost:8200/v1/sys/unseal
	pass Unseal_Key_5 | curl -sSL -X PUT -d @<(jq -nrR 'inputs|{key:.}|@json') http://localhost:8200/v1/sys/unseal

vault-seal:
	-env VAULT_TOKEN="$$(pass Initial_Root_Token)" VAULT_ADDR=http://localhost:8200 vault operator seal
	rm -f ~/.vault-token

down:
	-$(MAKE) vault-seal
	-cd ~/.password-store && sudo -u ubuntu git-crypt lock
	-echo yes | gh auth logout --hostname github.com

live:
	@env SSH_AUTH_SOCK="$(shell ls -td /tmp/vscode-ssh-auth-* 2>/dev/null | head -1)" ssh-add -L 2>/dev/null >/dev/null

monitor-loop:
	while true; do $(MAKE) monitor; sleep 30; done

monitor:
	@rm -f ~/.dead; \
		if ! $(MAKE) live 2>/dev/null >/dev/null; then \
			touch ~/.dead; \
			for a in $$(seq 1 60); do \
				if $(MAKE) live 2>/dev/null >/dev/null; then rm -f ~/.dead; break; fi; \
				echo "MAYBE DEAD $$a $$(date)"; sleep 5; done; \
		fi; \
		if test -f ~/.dead; then \
			~/bin/e $(MAKE) down; \
		fi; \
		ls -l ~/.alive || true; \
		if test -f ~/.alive && test "$$(find ~/.alive -mmin +120)"; then \
			~/bin/e $(MAKE) down; \
		fi

kumacp:
	env \
		KUMA_MODE=zone KUMA_MULTIZONE_ZONE_NAME="$$(uname -n)" \
		KUMA_MULTIZONE_ZONE_GLOBAL_ADDRESS=grpcs://169.254.32.1:5685 \
		kuma-cp run

kumatoken:
	kumactl generate dataplane-token \
		--mesh demo \
		--name hello \
		--tag kuma.io/service=hello \
		--valid-for 720h > /tmp/hello.token

kumahello:
	$(MAKE) kumatoken
	kuma-dp run \
		--cp-address=https://127.0.0.1:5678 \
		--dataplane-file=hello.yaml \
		--dataplane-token-file=/tmp/hello.token \
  		--dataplane-var address=$$(ifconfig eth0 | grep 'inet ' | awk '{print $$2}')
	rm -f /tmp/hello.token
